{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 13:21:08.741699: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743254468.896601 1816108 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743254468.940172 1816108 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-29 13:21:09.338230: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/rbeck1_sw/inter-intra-patient/venv_tf/lib/python3.12/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/home/rbeck1_sw/inter-intra-patient/venv_tf/lib/python3.12/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.18.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as spio\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from os.path import join as osj\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Embedding, Dense, Bidirectional, Input\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from  sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    level=logging.INFO,\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "random.seed(654)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B Processing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Read .mat files\n",
    "def read_mitbih(filename, max_time=100, classes=['F', 'N', 'S', 'V', 'Q'], max_label=100):\n",
    "\n",
    "    random.seed(654)\n",
    "    beats = [] \n",
    "    dict_samples = spio.loadmat(filename + '.mat')\n",
    "\n",
    "    # header = dict_samples['__header__']\n",
    "    # version = dict_samples['__version__']\n",
    "    # globals = dict_samples['__globals__'] \n",
    "    samples = dict_samples['s2s_mitbih'] # 2D array with 2 columns: ecg values and labels\n",
    "    values = samples[0]['seg_values'] # ecg values\n",
    "    labels = samples[0]['seg_labels'] # labels\n",
    "\n",
    "    # calculate the number of annotations and sequences\n",
    "    num_annots = sum([item.shape[0] for item in values]) # 109338\n",
    "    n_seqs = num_annots / max_time # 1093.38\n",
    "\n",
    "    # add all beats together\n",
    "    count_b = 0\n",
    "    nr_recordings = [] # number of recordings per patient (each recording contains 280 measurements)\n",
    "    for _, item in enumerate(values):\n",
    "        l = item.shape[0] # number of recordings per patient (each recording contains 280 measurements)\n",
    "        nr_recordings.append(l)\n",
    "        for itm in item:\n",
    "            if count_b == num_annots: # hence all recordings have been added\n",
    "                break\n",
    "            beats.append(itm[0]) # itm is one recording, with 280 measurements\n",
    "            count_b += 1\n",
    "\n",
    "    # add all labels together\n",
    "    count_l  = 0\n",
    "    t_labels = []\n",
    "    for _, item in enumerate(labels): \n",
    "        if len(t_labels) == num_annots: # break if all labels have been added\n",
    "            break\n",
    "        item = item[0]\n",
    "        # iterate over all recordings per patient\n",
    "        for lbl in item: \n",
    "            if count_l == num_annots: # break if all labels have been added\n",
    "                break\n",
    "            t_labels.append(str(lbl))\n",
    "            count_l += 1\n",
    "    \n",
    "    del values\n",
    "    # convert list to array & reshape\n",
    "    beats = np.asarray(beats)\n",
    "    t_labels = np.asarray(t_labels)  \n",
    "    shape_v = beats.shape # 109338 rows with each 280 entries (109338, 280, 1)\n",
    "    beats = np.reshape(beats, [shape_v[0], -1]) # new shape = (109338, 280)\n",
    "\n",
    "\n",
    "    # Create empty arrays for data and labels\n",
    "    random_beats  = np.asarray([],dtype=np.float64).reshape(0,shape_v[1])\n",
    "    random_labels = np.asarray([],dtype=np.dtype('|S1')).reshape(0,)\n",
    "\n",
    "    # iterate over all classes and truncate to max_label samples, so that all classes are equally represented\n",
    "    for cl in classes:\n",
    "        _label = np.where(t_labels == cl) # select indices that match the class\n",
    "        logger.info(f\"Class {cl} is represented {len(_label[0])}\")\n",
    "\n",
    "        # random permutation of indices\n",
    "        permute = np.random.permutation(len(_label[0])) \n",
    "        _label = _label[0][permute[:max_label]] # choose the first X indices\n",
    "        logger.info(f\"Class {cl} is now represented {len(_label)}\")\n",
    "\n",
    "        random_beats = np.concatenate((random_beats, beats[_label]))\n",
    "        random_labels = np.concatenate((random_labels, t_labels[_label]))\n",
    "\n",
    "    # shorten data to multiple of max_time\n",
    "    signals = random_beats[:int(len(random_beats)/ max_time) * max_time, :]\n",
    "    _labels  = random_labels[:int(len(random_beats) / max_time) * max_time]\n",
    "\n",
    "    #  reshape data into groups of max_time\n",
    "    data   = [signals[i:i + max_time] for i in range(0, len(signals), max_time)]\n",
    "    labels = [_labels[i:i + max_time] for i in range(0, len(_labels), max_time)]\n",
    "\n",
    "    permute = np.random.permutation(len(labels)) # random permutation of indices only\n",
    "\n",
    "    # transform from list to array\n",
    "    data   = np.asarray(data, dtype=object) \n",
    "    labels = np.asarray(labels, dtype=object)\n",
    "\n",
    "    # reorder data and labels according to random permute\n",
    "    data   = data[permute]\n",
    "    labels = labels[permute]\n",
    "\n",
    "    logger.info('Signals and labels processed!')\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "# F2 Normaliza data\n",
    "def normalize(data):\n",
    "        data = np.nan_to_num(data)  # removing NaNs and Infs\n",
    "        data = data - np.mean(data)\n",
    "        data = data / np.std(data)\n",
    "        return data\n",
    "\n",
    "# F3 shuffle\n",
    "def batch_data(x, y, batch_size):\n",
    "    shuffle = np.random.permutation(len(x))\n",
    "    start = 0\n",
    "    #     from IPython.core.debugger import Tracer; Tracer()()\n",
    "    x = x[shuffle]\n",
    "    y = y[shuffle]\n",
    "    while start + batch_size <= len(x):\n",
    "        yield x[start:start + batch_size], y[start:start + batch_size]\n",
    "        start += batch_size\n",
    "\n",
    "# F4 bool value check\n",
    "def str2bool(v):\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "# def count_prameters():\n",
    "    # logger.info(f\"# of Params: {np.sum([np.prod(v.get_shape().as_list()) for v in tf.compat.v1.trainable_variables()])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F5 calculate performance\n",
    "def evaluate_metrics(confusion_matrix):\n",
    "    # https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal\n",
    "    FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)\n",
    "    FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    TN = confusion_matrix.sum() - (FP + FN + TP)\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP / (TP + FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN / (TN + FP)\n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP / (TP + FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN / (TN + FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP / (FP + TN)\n",
    "    # False negative rate\n",
    "    FNR = FN / (TP + FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP / (TP + FP)\n",
    "\n",
    "    # Overall accuracy\n",
    "    ACC = (TP + TN) / (TP + FP + FN + TN)\n",
    "    # ACC_micro = (sum(TP) + sum(TN)) / (sum(TP) + sum(FP) + sum(FN) + sum(TN))\n",
    "    ACC_macro = np.mean(ACC) # to get a sense of effectiveness of our method on the small classes we computed this average (macro-average)\n",
    "\n",
    "    # F1 Score (Harmonic Mean of Precision & Recall)\n",
    "    F1 = 2 * (PPV * TPR) / (PPV + TPR)\n",
    "\n",
    "    return ACC_macro, ACC, TPR, TNR, PPV, NPV, FPR, FNR, FDR, F1\n",
    "\n",
    "# F6 Network\n",
    "def build_network(inputs, dec_inputs, char2numY, n_channels=10, input_depth=280, num_units=128, max_time=10, bidirectional=False):\n",
    "    # Reshape the inputs to match the Conv1D expected shape\n",
    "    _inputs = tf.reshape(inputs, [-1, n_channels, int(input_depth / n_channels)])\n",
    "    \n",
    "    # Convolutional and MaxPooling layers\n",
    "    conv1 = Conv1D(filters=32, kernel_size=2, strides=1, padding='same', activation='relu')(_inputs)\n",
    "    max_pool_1 = MaxPooling1D(pool_size=2, strides=2, padding='same')(conv1)\n",
    "\n",
    "    conv2 = Conv1D(filters=64, kernel_size=2, strides=1, padding='same', activation='relu')(max_pool_1)\n",
    "    max_pool_2 = MaxPooling1D(pool_size=2, strides=2, padding='same')(conv2)\n",
    "\n",
    "    conv3 = Conv1D(filters=128, kernel_size=2, strides=1, padding='same', activation='relu')(max_pool_2)\n",
    "\n",
    "    # Flatten the output of the Conv1D layers\n",
    "    shape = conv3.shape.as_list()\n",
    "    data_input_embed = tf.reshape(conv3, (-1, max_time, shape[1] * shape[2]))\n",
    "\n",
    "    # Embedding for the decoder\n",
    "    embed_size = 10\n",
    "    output_embedding = tf.Variable(tf.random.uniform((len(char2numY), embed_size), -1.0, 1.0), name='dec_embedding')\n",
    "    data_output_embed = tf.nn.embedding_lookup(params=output_embedding, ids=dec_inputs)\n",
    "\n",
    "    # Encoder\n",
    "    if not bidirectional:\n",
    "        # Regular LSTM\n",
    "        lstm_enc = LSTM(num_units, return_state=True)\n",
    "        _, last_state_h, last_state_c = lstm_enc(data_input_embed)\n",
    "        last_state = (last_state_c, last_state_h)\n",
    "    else:\n",
    "        # Bidirectional LSTM\n",
    "        lstm_enc = Bidirectional(LSTM(num_units, return_state=True))\n",
    "        _, forward_h, forward_c, backward_h, backward_c = lstm_enc(data_input_embed)\n",
    "        last_state_c = tf.concat([forward_c, backward_c], axis=-1)\n",
    "        last_state_h = tf.concat([forward_h, backward_h], axis=-1)\n",
    "        last_state = (last_state_c, last_state_h)\n",
    "\n",
    "    # Decoder\n",
    "    if not bidirectional:\n",
    "        lstm_dec = LSTM(num_units, return_sequences=True)\n",
    "    else:\n",
    "        lstm_dec = LSTM(2 * num_units, return_sequences=True)\n",
    "\n",
    "    dec_outputs = lstm_dec(data_output_embed, initial_state=last_state)\n",
    "\n",
    "    # Final Dense layer to produce logits\n",
    "    logits = Dense(len(char2numY))(dec_outputs)\n",
    "\n",
    "    return logits\n",
    "\n",
    "\n",
    "# # 7 configure biRNN\n",
    "# def build_network(inputs, dec_inputs,char2numY,n_channels=10,input_depth=280,num_units=128,max_time=10,bidirectional=False):\n",
    "#     _inputs = tf.reshape(inputs, [-1, n_channels, int(input_depth / n_channels)])\n",
    "#     # _inputs = tf.reshape(inputs, [-1,input_depth,n_channels])\n",
    "\n",
    "#     # #(batch*max_time, 280, 1) --> (N, 280, 18)\n",
    "#     conv1 = tf.compat.v1.layers.conv1d(inputs=_inputs, filters=32, kernel_size=2, strides=1,\n",
    "#                              padding='same', activation=tf.nn.relu)\n",
    "#     max_pool_1 = tf.compat.v1.layers.max_pooling1d(inputs=conv1, pool_size=2, strides=2, padding='same')\n",
    "\n",
    "#     conv2 = tf.compat.v1.layers.conv1d(inputs=max_pool_1, filters=64, kernel_size=2, strides=1,\n",
    "#                              padding='same', activation=tf.nn.relu)\n",
    "#     max_pool_2 = tf.compat.v1.layers.max_pooling1d(inputs=conv2, pool_size=2, strides=2, padding='same')\n",
    "\n",
    "#     conv3 = tf.compat.v1.layers.conv1d(inputs=max_pool_2, filters=128, kernel_size=2, strides=1,\n",
    "#                              padding='same', activation=tf.nn.relu)\n",
    "\n",
    "#     shape = conv3.get_shape().as_list()\n",
    "#     data_input_embed = tf.reshape(conv3, (-1, max_time, shape[1] * shape[2]))\n",
    "\n",
    "#     embed_size = 10  # 128 lstm_size # shape[1]*shape[2]\n",
    "\n",
    "#     # Embedding layers\n",
    "#     output_embedding = tf.Variable(tf.random.uniform((len(char2numY), embed_size), -1.0, 1.0), name='dec_embedding')\n",
    "#     data_output_embed = tf.nn.embedding_lookup(params=output_embedding, ids=dec_inputs)\n",
    "\n",
    "#     with tf.compat.v1.variable_scope(\"encoding\") as encoding_scope:\n",
    "#         if not bidirectional:\n",
    "\n",
    "#             # Regular approach with LSTM units\n",
    "#             lstm_enc = tf.compat.v1.nn.rnn_cell.LSTMCell(num_units)\n",
    "#             _, last_state = tf.compat.v1.nn.dynamic_rnn(lstm_enc, inputs=data_input_embed, dtype=tf.float32)\n",
    "\n",
    "#         else:\n",
    "\n",
    "#             # Using a bidirectional LSTM architecture instead\n",
    "#             enc_fw_cell = tf.compat.v1.nn.rnn_cell.LSTMCell(num_units)\n",
    "#             enc_bw_cell = tf.compat.v1.nn.rnn_cell.LSTMCell(num_units)\n",
    "\n",
    "#             ((enc_fw_out, enc_bw_out), (enc_fw_final, enc_bw_final)) = tf.compat.v1.nn.bidirectional_dynamic_rnn(\n",
    "#                 cell_fw=enc_fw_cell,\n",
    "#                 cell_bw=enc_bw_cell,\n",
    "#                 inputs=data_input_embed,\n",
    "#                 dtype=tf.float32)\n",
    "#             enc_fin_c = tf.concat((enc_fw_final.c, enc_bw_final.c), 1)\n",
    "#             enc_fin_h = tf.concat((enc_fw_final.h, enc_bw_final.h), 1)\n",
    "#             last_state = tf.nn.rnn_cell.LSTMStateTuple(c=enc_fin_c, h=enc_fin_h)\n",
    "\n",
    "#     with tf.compat.v1.variable_scope(\"decoding\") as decoding_scope:\n",
    "#         if not bidirectional:\n",
    "#             lstm_dec = tf.compat.v1.nn.rnn_cell.LSTMCell(num_units)\n",
    "#         else:\n",
    "#             lstm_dec = tf.compat.v1.nn.rnn_cell.LSTMCell(2 * num_units)\n",
    "\n",
    "#         dec_outputs, _ = tf.compat.v1.nn.dynamic_rnn(lstm_dec, inputs=data_output_embed, initial_state=last_state)\n",
    "\n",
    "#     logits = tf.compat.v1.layers.dense(dec_outputs, units=len(char2numY), use_bias=True)\n",
    "\n",
    "#     return logits\n",
    "\n",
    "# 7 Model evaluation\n",
    "def test_model(sess, logits, X_test, y_test, batch_size, char2numY, y_seq_length, n_classes, inputs, dec_inputs):\n",
    "    # source_batch, target_batch = next(batch_data(X_test, y_test, batch_size))\n",
    "    acc_track = []\n",
    "    sum_test_conf = []\n",
    "    count = 0\n",
    "    for batch_i, (source_batch, target_batch) in enumerate(batch_data(X_test, y_test, batch_size)):\n",
    "        logger.info(f\"Running batch: {count}\")\n",
    "        count = count + 1\n",
    "        dec_input = np.zeros((len(source_batch), 1)) + char2numY['<GO>']\n",
    "\n",
    "        for i in range(y_seq_length):\n",
    "            batch_logits = sess.run(logits, feed_dict={inputs: source_batch, dec_inputs: dec_input})\n",
    "            prediction = batch_logits[:, -1].argmax(axis=-1)\n",
    "            dec_input = np.hstack([dec_input, prediction[:, None]])\n",
    "\n",
    "        acc_track.append(dec_input[:, 1:] == target_batch[:, 1:])\n",
    "        y_true= target_batch[:, 1:].flatten()\n",
    "        y_pred = dec_input[:, 1:].flatten()\n",
    "        sum_test_conf.append(confusion_matrix(y_true, y_pred,labels=list(range(len(char2numY)-1))))\n",
    "\n",
    "    sum_test_conf= np.mean(np.array(sum_test_conf, dtype=np.float32), axis=0)\n",
    "    acc_avg, acc, sensitivity, specificity, ppv, npv, fpr, fnr, fdr, f1_score= evaluate_metrics(sum_test_conf)\n",
    "\n",
    "    logger.info(f\"Average Accuracy is: {acc_avg} on test set\")\n",
    "\n",
    "    for idx in range(n_classes):\n",
    "        logger.info(f\"\\t{classes[idx]} rhythm -> Sensitivity: {sensitivity[idx]}, Specificity : {specificity[idx]}, Precision (PPV) : {ppv[idx]}, Accuracy : {acc[idx]}\")\n",
    "\n",
    "    logger.info(f\"\\t Average -> Sensitivity: {np.mean(sensitivity)}, Specificity : {np.mean(specificity)}, Precision (PPV) : {np.mean(ppv)}, Accuracy : {np.mean(acc)}\")\n",
    "    \n",
    "    return acc_avg, acc, sensitivity, specificity, ppv, npv, fpr, fnr, fdr, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_program(args):\n",
    "def run_program(epochs, max_time, test_steps, batch_size, data_dir, bidirectional, num_units,\n",
    "            n_oversampling, checkpoint_dir, ckpt_name, classes):\n",
    "    \n",
    "    # # Arguments\n",
    "    # logger.info(args)\n",
    "    # max_time = args.max_time # 5 3 second best 10# 40 # 100\n",
    "    # epochs = args.epochs # 300\n",
    "    # batch_size = args.batch_size # 10\n",
    "    # num_units = args.num_units\n",
    "    # bidirectional = args.bidirectional\n",
    "    # # lstm_layers = args.lstm_layers\n",
    "    # n_oversampling = args.n_oversampling\n",
    "    # checkpoint_dir = args.checkpoint_dir\n",
    "    # ckpt_name = args.ckpt_name\n",
    "    # test_steps = args.test_steps\n",
    "    # classes= args.classes\n",
    "    # filename = args.data_dir\n",
    "    filename = data_dir\n",
    "\n",
    "    n_channels = 10\n",
    "\n",
    "    # STEP 1 Read .mat data\n",
    "    X, Y = read_mitbih(filename,max_time,classes=classes,max_label=100000)\n",
    "    input_depth = X.shape[2]\n",
    "    classes = np.unique(Y)\n",
    "    char2numY = dict(list(zip(classes, list(range(len(classes))))))\n",
    "    n_classes = len(classes)\n",
    "\n",
    "    logger.info(f\"Sequences: {len(X)}\")\n",
    "    logger.info(f\"Classes: {classes}\")\n",
    "\n",
    "    for cl in classes:\n",
    "        ind = np.where(classes == cl)[0][0]\n",
    "        logger.info(f\"Class: {cl} - count: {len(np.where(Y.flatten() == cl)[0])}\")\n",
    "\n",
    "    char2numY['<GO>'] = len(char2numY)\n",
    "    num2charY = dict(list(zip(list(char2numY.values()), list(char2numY.keys()))))\n",
    "\n",
    "    Y = [[char2numY['<GO>']] + [char2numY[y_] for y_ in date] for date in Y]\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    x_seq_length = len(X[0])\n",
    "    y_seq_length = len(Y[0])- 1\n",
    "\n",
    "    # Placeholders\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    inputs = tf.compat.v1.placeholder(tf.float32, [None, max_time, input_depth], name = 'inputs')\n",
    "    targets = tf.compat.v1.placeholder(tf.int32, (None, None), 'targets')\n",
    "    dec_inputs = tf.compat.v1.placeholder(tf.int32, (None, None), 'output')\n",
    "\n",
    "    logits = build_network(inputs, dec_inputs, char2numY, n_channels=n_channels, input_depth=input_depth, num_units=num_units, max_time=max_time,\n",
    "                  bidirectional=bidirectional)\n",
    "    # decoder_prediction = tf.argmax(logits, 2)\n",
    "    # confusion = tf.confusion_matrix(labels=tf.argmax(targets, 1), predictions=tf.argmax(logits, 2), num_classes=len(char2numY) - 1)# it is wrong\n",
    "    # mean_accuracy,update_mean_accuracy = tf.metrics.mean_per_class_accuracy(labels=targets, predictions=decoder_prediction, num_classes=len(char2numY) - 1)\n",
    "\n",
    "    with tf.compat.v1.name_scope(\"optimization\"):\n",
    "        # Loss function\n",
    "        vars = tf.compat.v1.trainable_variables()\n",
    "        beta = 0.001\n",
    "        lossL2 = tf.add_n([tf.nn.l2_loss(v) for v in vars if 'bias' not in v.name]) * beta\n",
    "        loss = tfa.seq2seq.sequence_loss(logits, targets, tf.ones([batch_size, y_seq_length]))\n",
    "        loss = tf.reduce_mean(input_tensor=loss + lossL2)\n",
    "         # Optimizer\n",
    "        optimizer = tf.compat.v1.train.RMSPropOptimizer(1e-3).minimize(loss)\n",
    "\n",
    "\n",
    "    # split the dataset into the training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # over-sampling: SMOTE\n",
    "    X_train = np.reshape(X_train,[X_train.shape[0]*X_train.shape[1],-1])\n",
    "    y_train= y_train[:,1:].flatten()\n",
    "\n",
    "    nums = []\n",
    "    for cl in classes:\n",
    "        ind = np.where(classes == cl)[0][0]\n",
    "        nums.append(len(np.where(y_train.flatten()==ind)[0]))\n",
    "\n",
    "    # ratio={0:nums[3],1:nums[1],2:nums[3],3:nums[3]} # the best with 11000 for N\n",
    "    ratio={0:n_oversampling,1:nums[1],2:n_oversampling,3:n_oversampling}\n",
    "    # Fixed by me: https://stackoverflow.com/questions/62225793/typeerror-init-got-an-unexpected-keyword-argument-ratio-when-using-smot\n",
    "    # version with error: sm = SMOTE(random_state=12,ratio=ratio)\n",
    "    sm = SMOTE(random_state=12,sampling_strategy=ratio)\n",
    "    # Fixed by me: https://stackoverflow.com/questions/66364406/attributeerror-smote-object-has-no-attribute-fit-sample\n",
    "    # version with error: X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "    X_train = X_train[:int(X_train.shape[0]/max_time)*max_time,:]\n",
    "    y_train = y_train[:int(X_train.shape[0]/max_time)*max_time]\n",
    "\n",
    "    X_train = np.reshape(X_train,[-1,X_test.shape[1],X_test.shape[2]])\n",
    "    y_train = np.reshape(y_train,[-1,y_test.shape[1]-1,])\n",
    "\n",
    "    y_train= [[char2numY['<GO>']] + [y_ for y_ in date] for date in y_train]\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    # Logging instead of prints (Ricarda)\n",
    "    logger.info(f\"Classes in the training set: {classes}\")\n",
    "    for cl in classes:\n",
    "        ind = np.where(classes == cl)[0][0]\n",
    "        logger.info(f\"Class: {cl}, Count: {len(np.where(y_train.flatten() == ind)[0])}\")\n",
    "\n",
    "    logger.info(\"------------------ y_train samples --------------------\")\n",
    "    for ii in range(2):\n",
    "        logger.info(''.join([num2charY[y_] for y_ in list(y_train[ii+5])]))\n",
    "\n",
    "    logger.info(f\"Classes in the test set: {classes}\")\n",
    "    for cl in classes:\n",
    "        ind = np.where(classes == cl)[0][0]\n",
    "        logger.info(f\"Class: {cl}, Count: {len(np.where(y_test.flatten() == ind)[0])})\")\n",
    "\n",
    "    logger.info(\"------------------ y_test samples --------------------\")\n",
    "    for ii in range(2):\n",
    "        logger.info(''.join([num2charY[y_] for y_ in list(y_test[ii+5])]))\n",
    "\n",
    "    # moved to code instead of function (Ricarda)\n",
    "    logger.info(f\"# of Params: {np.sum([np.prod(v.get_shape().as_list()) for v in tf.compat.v1.trainable_variables()])}\")\n",
    "\n",
    "    if (os.path.exists(checkpoint_dir) == False):\n",
    "        os.mkdir(checkpoint_dir)\n",
    "\n",
    "    # train the graph\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        sess.run(tf.compat.v1.global_variables_initializer())\n",
    "        sess.run(tf.compat.v1.local_variables_initializer())\n",
    "\n",
    "        saver = tf.compat.v1.train.Saver()\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "\n",
    "        test_results = {}\n",
    "        # Restore if available\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            \n",
    "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "            saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "            acc_avg, acc, sensitivity, specificity, ppv, npv, fpr, fnr, fdr, f1_score = test_model(sess, logits, X_test, y_test, batch_size, char2numY, y_seq_length, n_classes, inputs, dec_inputs) # definition moved to function definitions (Ricarda)\n",
    "            test_results[\"avg_acc\"] = acc_avg\n",
    "            test_results[\"acc\"] = acc\n",
    "            test_results[\"sens\"] = sensitivity\n",
    "            test_results[\"spec\"] = specificity\n",
    "            test_results[\"prec\"] = ppv\n",
    "            test_results[\"neg_pred_value\"] = npv\n",
    "            test_results[\"false_pos_rate\"] = fpr\n",
    "            test_results[\"false_neg_rate\"] = fnr\n",
    "            test_results[\"false_det_rate\"] = fdr\n",
    "            test_results[\"f1_score\"]       = f1_score\n",
    "\n",
    "            with open(osj(\"..\", \"results\", \"intrapatient\", f\"test_results.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(test_results, f) \n",
    "        else:\n",
    "\n",
    "            loss_track = []\n",
    "            for epoch_i in range(epochs):\n",
    "                start_time = time.time()\n",
    "                train_acc = []\n",
    "                for batch_i, (source_batch, target_batch) in enumerate(batch_data(X_train, y_train, batch_size)):\n",
    "                    _, batch_loss, batch_logits = sess.run([optimizer, loss, logits],\n",
    "                        feed_dict = {inputs: source_batch,\n",
    "                                     dec_inputs: target_batch[:, :-1],\n",
    "                                     targets: target_batch[:, 1:]})\n",
    "                    loss_track.append(batch_loss)\n",
    "                    train_acc.append(batch_logits.argmax(axis=-1) == target_batch[:,1:])\n",
    "\n",
    "                accuracy = np.mean(train_acc)\n",
    "                logger.info(f\"Epoch {epoch_i+1} Loss: {batch_loss} Accuracy: {accuracy} Epoch duration: {time.time() - start_time}s started at {start_time}\")\n",
    "\n",
    "                if epoch_i%test_steps==0:\n",
    "                    acc_avg, acc, sensitivity, specificity, ppv, npv, fpr, fnr, fdr, f1_score = test_model(sess, logits, X_test, y_test, batch_size, char2numY, y_seq_length, n_classes, inputs, dec_inputs) # definition moved to function definitions (Ricarda)\n",
    "                    test_results[\"avg_acc\"] = acc_avg\n",
    "                    test_results[\"acc\"] = acc\n",
    "                    test_results[\"sens\"] = sensitivity\n",
    "                    test_results[\"spec\"] = specificity\n",
    "                    test_results[\"prec\"] = ppv\n",
    "                    test_results[\"neg_pred_value\"] = npv\n",
    "                    test_results[\"false_pos_rate\"] = fpr\n",
    "                    test_results[\"false_neg_rate\"] = fnr\n",
    "                    test_results[\"false_det_rate\"] = fdr\n",
    "                    test_results[\"f1_score\"]       = f1_score\n",
    "                    \n",
    "                    with open(osj(\"..\", \"results\", \"intrapatient\", f\"test_results.pkl\"), \"wb\") as f:\n",
    "                        pickle.dump(test_results, f) \n",
    "\n",
    "                    logger.info(f\"Loss {loss} after {epoch_i+1} epochs (batch_size={batch_size})\")\n",
    "                    save_path = os.path.join(checkpoint_dir, ckpt_name)\n",
    "                    saver.save(sess, save_path)\n",
    "                    logger.info(f\"Model saved in path {save_path}\")\n",
    "\n",
    "            plt.plot(loss_track)\n",
    "            plt.show()\n",
    "        \n",
    "        logger.info(f\"Model training finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual run of program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 13:18:10 - INFO - Class F is represented 802\n",
      "2025-03-18 13:18:10 - INFO - Class F is now represented 802\n",
      "2025-03-18 13:18:10 - INFO - Class N is represented 90502\n",
      "2025-03-18 13:18:10 - INFO - Class N is now represented 90502\n",
      "2025-03-18 13:18:10 - INFO - Class S is represented 2777\n",
      "2025-03-18 13:18:10 - INFO - Class S is now represented 2777\n",
      "2025-03-18 13:18:10 - INFO - Class V is represented 7226\n",
      "2025-03-18 13:18:10 - INFO - Class V is now represented 7226\n",
      "2025-03-18 13:18:11 - INFO - Signals and labels processed!\n",
      "2025-03-18 13:18:12 - INFO - Sequences: 10130\n",
      "2025-03-18 13:18:12 - INFO - Classes: ['F' 'N' 'S' 'V']\n",
      "2025-03-18 13:18:12 - INFO - Class: F - count: 802\n",
      "2025-03-18 13:18:12 - INFO - Class: N - count: 90502\n",
      "2025-03-18 13:18:12 - INFO - Class: S - count: 2777\n",
      "2025-03-18 13:18:12 - INFO - Class: V - count: 7219\n",
      "/home/rbeck1_sw/inter-intra-patient/venv_tf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "2025-03-18 13:18:14 - INFO - Classes in the training set: ['F' 'N' 'S' 'V']\n",
      "2025-03-18 13:18:14 - INFO - Class: F, Count: 10000\n",
      "2025-03-18 13:18:14 - INFO - Class: N, Count: 72312\n",
      "2025-03-18 13:18:14 - INFO - Class: S, Count: 10000\n",
      "2025-03-18 13:18:14 - INFO - Class: V, Count: 9998\n",
      "2025-03-18 13:18:14 - INFO - ------------------ y_train samples --------------------\n",
      "2025-03-18 13:18:14 - INFO - <GO>NNNNNNNNNN\n",
      "2025-03-18 13:18:14 - INFO - <GO>NNNNNNNNNN\n",
      "2025-03-18 13:18:14 - INFO - Classes in the test set: ['F' 'N' 'S' 'V']\n",
      "2025-03-18 13:18:14 - INFO - Class: F, Count: 190)\n",
      "2025-03-18 13:18:14 - INFO - Class: N, Count: 18190)\n",
      "2025-03-18 13:18:14 - INFO - Class: S, Count: 490)\n",
      "2025-03-18 13:18:14 - INFO - Class: V, Count: 1390)\n",
      "2025-03-18 13:18:14 - INFO - ------------------ y_test samples --------------------\n",
      "2025-03-18 13:18:14 - INFO - <GO>NNNNNNNNNN\n",
      "2025-03-18 13:18:14 - INFO - <GO>NNNNNNNNNN\n",
      "2025-03-18 13:18:14 - INFO - # of Params: 714030\n",
      "I0000 00:00:1742303894.017470  645483 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1035 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "2025-03-18 13:18:17 - INFO - Epoch 1 Loss: 0.07364214956760406 Accuracy: 0.9108708414872798 Epoch duration: 2.7302756309509277s started at 1742303894.381123\n",
      "2025-03-18 13:18:17 - INFO - Running batch: 0\n",
      "2025-03-18 13:18:17 - INFO - Running batch: 1\n",
      "2025-03-18 13:18:17 - INFO - Running batch: 2\n",
      "2025-03-18 13:18:17 - INFO - Running batch: 3\n",
      "2025-03-18 13:18:17 - INFO - Running batch: 4\n",
      "2025-03-18 13:18:17 - INFO - Running batch: 5\n",
      "2025-03-18 13:18:17 - INFO - Running batch: 6\n",
      "2025-03-18 13:18:17 - INFO - Running batch: 7\n",
      "2025-03-18 13:18:17 - INFO - Running batch: 8\n",
      "2025-03-18 13:18:17 - INFO - Running batch: 9\n",
      "2025-03-18 13:18:17 - INFO - Running batch: 10\n",
      "2025-03-18 13:18:17 - INFO - Running batch: 11\n",
      "2025-03-18 13:18:17 - INFO - Running batch: 12\n",
      "2025-03-18 13:18:17 - INFO - Running batch: 13\n",
      "2025-03-18 13:18:17 - INFO - Running batch: 14\n",
      "2025-03-18 13:18:17 - INFO - Running batch: 15\n",
      "2025-03-18 13:18:17 - INFO - Running batch: 16\n",
      "2025-03-18 13:18:17 - INFO - Running batch: 17\n",
      "2025-03-18 13:18:17 - INFO - Running batch: 18\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 19\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 20\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 21\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 22\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 23\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 24\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 25\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 26\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 27\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 28\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 29\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 30\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 31\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 32\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 33\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 34\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 35\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 36\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 37\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 38\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 39\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 40\n",
      "2025-03-18 13:18:18 - INFO - Running batch: 41\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 42\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 43\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 44\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 45\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 46\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 47\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 48\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 49\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 50\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 51\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 52\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 53\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 54\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 55\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 56\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 57\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 58\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 59\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 60\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 61\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 62\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 63\n",
      "2025-03-18 13:18:19 - INFO - Running batch: 64\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 65\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 66\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 67\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 68\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 69\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 70\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 71\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 72\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 73\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 74\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 75\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 76\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 77\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 78\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 79\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 80\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 81\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 82\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 83\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 84\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 85\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 86\n",
      "2025-03-18 13:18:20 - INFO - Running batch: 87\n",
      "2025-03-18 13:18:21 - INFO - Running batch: 88\n",
      "2025-03-18 13:18:21 - INFO - Running batch: 89\n",
      "2025-03-18 13:18:21 - INFO - Running batch: 90\n",
      "2025-03-18 13:18:21 - INFO - Running batch: 91\n",
      "2025-03-18 13:18:21 - INFO - Running batch: 92\n",
      "2025-03-18 13:18:21 - INFO - Running batch: 93\n",
      "2025-03-18 13:18:21 - INFO - Running batch: 94\n",
      "2025-03-18 13:18:21 - INFO - Running batch: 95\n",
      "2025-03-18 13:18:21 - INFO - Running batch: 96\n",
      "2025-03-18 13:18:21 - INFO - Running batch: 97\n",
      "2025-03-18 13:18:21 - INFO - Running batch: 98\n",
      "2025-03-18 13:18:21 - INFO - Running batch: 99\n",
      "2025-03-18 13:18:21 - INFO - Running batch: 100\n",
      "2025-03-18 13:18:21 - INFO - Average Accuracy is: 0.9987623691558838 on test set\n",
      "2025-03-18 13:18:21 - INFO - \tF rhythm -> Sensitivity: 1.0, Specificity : 0.9985007643699646, Precision (PPV) : 0.8636363744735718, Accuracy : 0.9985148906707764\n",
      "2025-03-18 13:18:21 - INFO - \tN rhythm -> Sensitivity: 0.9977949261665344, Specificity : 0.9951454401016235, Precision (PPV) : 0.9994478225708008, Accuracy : 0.9975247383117676\n",
      "2025-03-18 13:18:21 - INFO - \tS rhythm -> Sensitivity: 0.9795918464660645, Specificity : 1.0, Precision (PPV) : 1.0, Accuracy : 0.9995049238204956\n",
      "2025-03-18 13:18:21 - INFO - \tV rhythm -> Sensitivity: 1.0, Specificity : 0.9994686245918274, Precision (PPV) : 0.9928057789802551, Accuracy : 0.9995049238204956\n",
      "2025-03-18 13:18:21 - INFO - \t Average -> Sensitivity: 0.9943466782569885, Specificity : 0.9982786774635315, Precision (PPV) : 0.9639725089073181, Accuracy : 0.9987623691558838\n",
      "2025-03-18 13:18:21 - INFO - Loss Tensor(\"optimization_1/Mean:0\", shape=(), dtype=float32) after 1 epochs (batch_size=20)\n",
      "2025-03-18 13:18:21 - INFO - Model saved in path checkpoints-seq2seq/seq2seq_mitbih.ckpt\n",
      "2025-03-18 13:18:24 - INFO - Epoch 2 Loss: 0.04484925419092178 Accuracy: 0.9968688845401175 Epoch duration: 2.631859540939331s started at 1742303901.7942858\n",
      "2025-03-18 13:18:27 - INFO - Epoch 3 Loss: 0.026580238714814186 Accuracy: 0.9971819960861057 Epoch duration: 2.603832483291626s started at 1742303904.4268694\n",
      "2025-03-18 13:18:29 - INFO - Epoch 4 Loss: 0.18751102685928345 Accuracy: 0.9968297455968689 Epoch duration: 2.565978527069092s started at 1742303907.0313966\n",
      "2025-03-18 13:18:31 - INFO - Epoch 5 Loss: 0.019307967275381088 Accuracy: 0.9976614481409002 Epoch duration: 2.122826099395752s started at 1742303909.597918\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 13:18:31 - INFO - Model training finished!\n"
     ]
    }
   ],
   "source": [
    "epochs         = 5\n",
    "max_time       = 10\n",
    "test_steps     = 10\n",
    "batch_size     = 20\n",
    "data_dir       = '../data/s2s_mitbih_aami'\n",
    "# data_dir       = '../datapreprocessing_Matlab/s2s_mitbih_aami' # processed manually\n",
    "bidirectional  = False\n",
    "# lstm_layers    = 2\n",
    "num_units      = 128\n",
    "n_oversampling = 10000\n",
    "checkpoint_dir = 'checkpoints-seq2seq'\n",
    "ckpt_name      = 'seq2seq_mitbih.ckpt'\n",
    "classes        = ['F','N','S','V']\n",
    "\n",
    "filename = data_dir\n",
    "n_channels = 10\n",
    "\n",
    "# STEP 1 Read .mat data\n",
    "X, Y = read_mitbih(filename,max_time,classes=classes,max_label=100000)\n",
    "input_depth = X.shape[2]\n",
    "classes = np.unique(Y)\n",
    "char2numY = dict(list(zip(classes, list(range(len(classes))))))\n",
    "n_classes = len(classes)\n",
    "\n",
    "logger.info(f\"Sequences: {len(X)}\")\n",
    "logger.info(f\"Classes: {classes}\")\n",
    "\n",
    "for cl in classes:\n",
    "    ind = np.where(classes == cl)[0][0]\n",
    "    logger.info(f\"Class: {cl} - count: {len(np.where(Y.flatten() == cl)[0])}\")\n",
    "\n",
    "char2numY['<GO>'] = len(char2numY)\n",
    "num2charY = dict(list(zip(list(char2numY.values()), list(char2numY.keys()))))\n",
    "\n",
    "Y = [[char2numY['<GO>']] + [char2numY[y_] for y_ in date] for date in Y]\n",
    "Y = np.array(Y)\n",
    "\n",
    "x_seq_length = len(X[0])\n",
    "y_seq_length = len(Y[0])- 1\n",
    "\n",
    "# Step 2 Prepare network\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "inputs = tf.compat.v1.placeholder(tf.float32, [None, max_time, input_depth], name = 'inputs')\n",
    "targets = tf.compat.v1.placeholder(tf.int32, (None, None), 'targets')\n",
    "dec_inputs = tf.compat.v1.placeholder(tf.int32, (None, None), 'output')\n",
    "\n",
    "logits = build_network(inputs, dec_inputs, char2numY, n_channels=n_channels, input_depth=input_depth, num_units=num_units, max_time=max_time,\n",
    "                bidirectional=bidirectional)\n",
    "\n",
    "\n",
    "# STEP 3 Prepare the data for training\n",
    "with tf.compat.v1.name_scope(\"optimization\"):\n",
    "    # Loss function\n",
    "    vars = tf.compat.v1.trainable_variables()\n",
    "    beta = 0.001\n",
    "    lossL2 = tf.add_n([tf.nn.l2_loss(v) for v in vars if 'bias' not in v.name]) * beta\n",
    "    loss = tfa.seq2seq.sequence_loss(logits, targets, tf.ones([batch_size, y_seq_length]))\n",
    "    loss = tf.reduce_mean(input_tensor=loss + lossL2)\n",
    "        # Optimizer\n",
    "    optimizer = tf.compat.v1.train.RMSPropOptimizer(1e-3).minimize(loss)\n",
    "\n",
    "\n",
    "# split the dataset into the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# over-sampling: SMOTE\n",
    "X_train = np.reshape(X_train,[X_train.shape[0]*X_train.shape[1],-1])\n",
    "y_train= y_train[:,1:].flatten()\n",
    "\n",
    "nums = []\n",
    "for cl in classes:\n",
    "    ind = np.where(classes == cl)[0][0]\n",
    "    nums.append(len(np.where(y_train.flatten()==ind)[0]))\n",
    "\n",
    "# ratio={0:nums[3],1:nums[1],2:nums[3],3:nums[3]} # the best with 11000 for N\n",
    "ratio={0:n_oversampling,1:nums[1],2:n_oversampling,3:n_oversampling}\n",
    "# Fixed by Ricarda: https://stackoverflow.com/questions/62225793/typeerror-init-got-an-unexpected-keyword-argument-ratio-when-using-smot\n",
    "# version with error: sm = SMOTE(random_state=12,ratio=ratio)\n",
    "sm = SMOTE(random_state=12,sampling_strategy=ratio)\n",
    "# Fixed by Ricarda: https://stackoverflow.com/questions/66364406/attributeerror-smote-object-has-no-attribute-fit-sample\n",
    "# version with error: X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "X_train = X_train[:int(X_train.shape[0]/max_time)*max_time,:]\n",
    "y_train = y_train[:int(X_train.shape[0]/max_time)*max_time]\n",
    "\n",
    "X_train = np.reshape(X_train,[-1,X_test.shape[1],X_test.shape[2]])\n",
    "y_train = np.reshape(y_train,[-1,y_test.shape[1]-1,])\n",
    "\n",
    "y_train= [[char2numY['<GO>']] + [y_ for y_ in date] for date in y_train]\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "logger.info(f\"Classes in the training set: {classes}\")\n",
    "for cl in classes:\n",
    "    ind = np.where(classes == cl)[0][0]\n",
    "    logger.info(f\"Class: {cl}, Count: {len(np.where(y_train.flatten() == ind)[0])}\")\n",
    "\n",
    "logger.info(\"------------------ y_train samples --------------------\")\n",
    "for ii in range(2):\n",
    "    logger.info(''.join([num2charY[y_] for y_ in list(y_train[ii+5])]))\n",
    "\n",
    "logger.info(f\"Classes in the test set: {classes}\")\n",
    "for cl in classes:\n",
    "    ind = np.where(classes == cl)[0][0]\n",
    "    logger.info(f\"Class: {cl}, Count: {len(np.where(y_test.flatten() == ind)[0])})\")\n",
    "\n",
    "logger.info(\"------------------ y_test samples --------------------\")\n",
    "for ii in range(2):\n",
    "    logger.info(''.join([num2charY[y_] for y_ in list(y_test[ii+5])]))\n",
    "\n",
    "# moved to code instead of function (Ricarda)\n",
    "logger.info(f\"# of Params: {np.sum([np.prod(v.get_shape().as_list()) for v in tf.compat.v1.trainable_variables()])}\")\n",
    "\n",
    "if (os.path.exists(checkpoint_dir) == False):\n",
    "    os.mkdir(checkpoint_dir)\n",
    "\n",
    "# Step 4: Train the graph\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    sess.run(tf.compat.v1.local_variables_initializer())\n",
    "\n",
    "    saver = tf.compat.v1.train.Saver()\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "\n",
    "    test_results = {}\n",
    "    \n",
    "    # Restore if available\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        \n",
    "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "        acc_avg, acc, sensitivity, specificity, ppv, npv, fpr, fnr, fdr, f1_score = test_model(sess, logits, X_test, y_test, batch_size, char2numY, y_seq_length, n_classes, inputs, dec_inputs) # definition moved to function definitions (Ricarda)\n",
    "        test_results[\"avg_acc\"] = acc_avg\n",
    "        test_results[\"acc\"] = acc\n",
    "        test_results[\"sens\"] = sensitivity\n",
    "        test_results[\"spec\"] = specificity\n",
    "        test_results[\"prec\"] = ppv\n",
    "        test_results[\"neg_pred_value\"] = npv\n",
    "        test_results[\"false_pos_rate\"] = fpr\n",
    "        test_results[\"false_neg_rate\"] = fnr\n",
    "        test_results[\"false_det_rate\"] = fdr\n",
    "        test_results[\"f1_score\"]       = f1_score\n",
    "\n",
    "        with open(osj(\"..\", \"results\", \"intrapatient\", f\"test_results.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(test_results, f) \n",
    "    else:\n",
    "\n",
    "        loss_track = []\n",
    "        for epoch_i in range(epochs):\n",
    "            start_time = time.time()\n",
    "            train_acc = []\n",
    "            for batch_i, (source_batch, target_batch) in enumerate(batch_data(X_train, y_train, batch_size)):\n",
    "                _, batch_loss, batch_logits = sess.run([optimizer, loss, logits],\n",
    "                    feed_dict = {inputs: source_batch,\n",
    "                                    dec_inputs: target_batch[:, :-1],\n",
    "                                    targets: target_batch[:, 1:]})\n",
    "                loss_track.append(batch_loss)\n",
    "                train_acc.append(batch_logits.argmax(axis=-1) == target_batch[:,1:])\n",
    "\n",
    "            accuracy = np.mean(train_acc)\n",
    "            logger.info(f\"Epoch {epoch_i+1} Loss: {batch_loss} Accuracy: {accuracy} Epoch duration: {time.time() - start_time}s started at {start_time}\")\n",
    "\n",
    "            if epoch_i%test_steps==0:\n",
    "                acc_avg, acc, sensitivity, specificity, ppv, npv, fpr, fnr, fdr, f1_score = test_model(sess, logits, X_test, y_test, batch_size, char2numY, y_seq_length, n_classes, inputs, dec_inputs) # definition moved to function definitions (Ricarda)\n",
    "                test_results[\"avg_acc\"] = acc_avg\n",
    "                test_results[\"acc\"] = acc\n",
    "                test_results[\"sens\"] = sensitivity\n",
    "                test_results[\"spec\"] = specificity\n",
    "                test_results[\"prec\"] = ppv\n",
    "                test_results[\"neg_pred_value\"] = npv\n",
    "                test_results[\"false_pos_rate\"] = fpr\n",
    "                test_results[\"false_neg_rate\"] = fnr\n",
    "                test_results[\"false_det_rate\"] = fdr\n",
    "                test_results[\"f1_score\"]       = f1_score\n",
    "                \n",
    "                with open(osj(\"..\", \"results\", \"intrapatient\", f\"test_results.pkl\"), \"wb\") as f:\n",
    "                    pickle.dump(test_results, f) \n",
    "\n",
    "                logger.info(f\"Loss {loss} after {epoch_i+1} epochs (batch_size={batch_size})\")\n",
    "                save_path = os.path.join(checkpoint_dir, ckpt_name)\n",
    "                saver.save(sess, save_path)\n",
    "                logger.info(f\"Model saved in path {save_path}\")\n",
    "\n",
    "        plt.plot(loss_track)\n",
    "        plt.show()\n",
    "    \n",
    "    logger.info(f\"Model training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 10:57:31 - INFO - Class F is represented 802\n",
      "2025-03-29 10:57:31 - INFO - Class F is now represented 802\n",
      "2025-03-29 10:57:31 - INFO - Class N is represented 90502\n",
      "2025-03-29 10:57:31 - INFO - Class N is now represented 90502\n",
      "2025-03-29 10:57:31 - INFO - Class S is represented 2777\n",
      "2025-03-29 10:57:31 - INFO - Class S is now represented 2777\n",
      "2025-03-29 10:57:31 - INFO - Class V is represented 7226\n",
      "2025-03-29 10:57:31 - INFO - Class V is now represented 7226\n",
      "2025-03-29 10:57:32 - INFO - Signals and labels processed!\n"
     ]
    }
   ],
   "source": [
    "epochs         = 5\n",
    "max_time       = 10\n",
    "test_steps     = 10\n",
    "batch_size     = 20\n",
    "data_dir       = '../data/s2s_mitbih_aami'\n",
    "bidirectional  = False\n",
    "num_units      = 128\n",
    "n_oversampling = 10000\n",
    "checkpoint_dir = 'checkpoints-seq2seq'\n",
    "ckpt_name      = 'seq2seq_mitbih.ckpt'\n",
    "classes        = ['F','N','S','V']\n",
    "\n",
    "filename = data_dir\n",
    "n_channels = 10\n",
    "\n",
    "X, Y = read_mitbih(filename,max_time,classes=classes,max_label=100000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
